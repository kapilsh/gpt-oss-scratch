{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e997de60",
   "metadata": {},
   "outputs": [],
   "source": "# Import required modules\nfrom rms_norm import create_rmsnorm_analyzer, print_flop_analysis\nfrom plotting_utils import create_complete_analysis_report"
  },
  {
   "cell_type": "markdown",
   "id": "13519aa2",
   "metadata": {},
   "source": "# RMSNorm Analysis Notebook\n\nThis notebook provides comprehensive performance analysis for the RMSNorm module, including:\n- FLOP calculations and memory bandwidth analysis\n- Scaling behavior across batch sizes, sequence lengths, and embedding dimensions  \n- Performance visualizations and optimization insights\n\nThe computational code has been moved to `rms_norm.py` for better modularity and reuse."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c862567",
   "metadata": {},
   "outputs": [],
   "source": "# FLOP Analysis for Common Configurations\n\n# Define typical transformer configurations\nconfigurations = [\n    {\"name\": \"Small\", \"B\": 8, \"S\": 512, \"D\": 768},\n    {\"name\": \"Base\", \"B\": 16, \"S\": 1024, \"D\": 1024}, \n    {\"name\": \"Large\", \"B\": 32, \"S\": 2048, \"D\": 4096},\n    {\"name\": \"XL\", \"B\": 64, \"S\": 4096, \"D\": 8192},\n]\n\n# Print FLOP analysis\nprint_flop_analysis(configurations)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sl60i0dut8p",
   "metadata": {},
   "outputs": [],
   "source": "# Quick Memory Bandwidth Test\n\nimport torch\n\nif torch.cuda.is_available():\n    print(\"Running quick memory bandwidth test on a few configurations...\")\n    \n    # Create RMSNorm analyzer\n    analyzer = create_rmsnorm_analyzer()\n    \n    # Quick test configurations (cache-busting sizes)\n    quick_configs = [\n        (32, 2048, 4096),   # ~0.5GB\n        (64, 2048, 4096),   # ~1.0GB  \n        (32, 4096, 4096),   # ~1.0GB\n    ]\n    \n    from rms_norm import BenchmarkConfig\n    \n    print(f\"\\nTesting {len(quick_configs)} cache-busting configurations:\")\n    print(\"-\" * 60)\n    \n    for i, (B, S, D) in enumerate(quick_configs, 1):\n        tensor_size_gb = B * S * D * 2 / 1e9  # FP16\n        print(f\"\\nConfig {i}: B={B}, S={S}, D={D}\")\n        print(f\"Tensor size: {tensor_size_gb:.2f} GB\")\n        \n        try:\n            # Test with fast config for demonstration\n            config = BenchmarkConfig(warmup_runs=3, benchmark_runs=10)\n            bandwidth, actual_size = analyzer.safe_benchmark(B, S, D, config)\n            \n            if bandwidth > 0:\n                utilization = (bandwidth / 1008) * 100  # RTX 4090 peak\n                print(f\"✅ Bandwidth: {bandwidth:.1f} GB/s ({utilization:.1f}% utilization)\")\n            else:\n                print(\"❌ OOM or benchmark failed\")\n                \n        except Exception as e:\n            print(f\"❌ Error: {e}\")\n            \n        # Clear memory\n        torch.cuda.empty_cache()\n        \nelse:\n    print(\"CUDA not available - skipping bandwidth test\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y9p0wpkfi7n",
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive Analysis with Visualizations\n\nimport torch\n\nif torch.cuda.is_available():\n    print(\"Running comprehensive RMSNorm bandwidth analysis...\")\n    print(\"This will test 1000+ parameter combinations and generate detailed visualizations.\")\n    print(\"⚠️  This may take 30-90 minutes depending on GPU memory and configuration count.\")\n    print(\"\\nTo run the analysis, uncomment and execute the code below:\")\n    \n    analysis_code = '''\n# Create RMSNorm analyzer\nanalyzer = create_rmsnorm_analyzer()\n\n# Run comprehensive analysis with expanded parameter ranges\nfrom rms_norm import BenchmarkConfig\n\nconfig = BenchmarkConfig(\n    warmup_runs=1,           # Fast for large-scale testing\n    benchmark_runs=3,        # Fast for large-scale testing  \n    memory_factor=6,         # RMSNorm memory access pattern\n    percentile_filter=(0.1, 0.9)  # Filter outliers\n)\n\n# Run the analysis\ndf_results = analyzer.run_comprehensive_analysis(\n    config=config,\n    expanded_ranges=True,    # Use expanded parameter ranges (powers of 2 + multiples)\n    peak_bandwidth_gbps=1008 # RTX 4090 theoretical peak\n)\n\n# Create complete analysis report with plots\ncreate_complete_analysis_report(\n    df_results,\n    module_name=\"RMSNorm\",\n    peak_bandwidth_gbps=1008,\n    show_plots=True,\n    top_n=15\n)\n\n# Store results for further analysis\nglobals()[\"bandwidth_results\"] = df_results\nprint(f\"\\\\nResults stored in 'bandwidth_results' variable with {len(df_results):,} configurations\")\n'''\n\n    print(f\"Code to run comprehensive analysis:\")\n    print(\"-\" * 50) \n    print(analysis_code)\n    \nelse:\n    print(\"CUDA not available - cannot run comprehensive GPU analysis\")\n    print(\"The analysis requires a CUDA-capable GPU for memory bandwidth measurements.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}