{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2746414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_oss.torch.model import Transformer\n",
    "from gpt_oss.triton.model import Transformer as TritonTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1214cbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ksharma/dev/git/gpt-oss-scratch/gpt-oss-20b/original'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "checkpoint_path = os.path.join(os.getcwd(), \"gpt-oss-20b/original\")\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a84b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(num_hidden_layers=24,\n",
      "            num_experts=32,\n",
      "            experts_per_token=4,\n",
      "            vocab_size=201088,\n",
      "            hidden_size=2880,\n",
      "            intermediate_size=2880,\n",
      "            swiglu_limit=7.0,\n",
      "            head_dim=64,\n",
      "            num_attention_heads=64,\n",
      "            num_key_value_heads=8,\n",
      "            sliding_window=128,\n",
      "            initial_context_length=4096,\n",
      "            rope_theta=150000,\n",
      "            rope_scaling_factor=32.0,\n",
      "            rope_ntk_alpha=1,\n",
      "            rope_ntk_beta=32)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gpt_oss.torch.model import ModelConfig\n",
    "import pprint\n",
    "\n",
    "\n",
    "config_path = os.path.join(checkpoint_path, \"config.json\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    json_config = json.load(f)\n",
    "    config = ModelConfig(**json_config)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25646e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep  5 09:56:08 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   45C    P8              23W / 450W |    811MiB / 24564MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2087      G   /usr/lib/xorg/Xorg                          327MiB |\n",
      "|    0   N/A  N/A      2312      G   /usr/bin/gnome-shell                        109MiB |\n",
      "|    0   N/A  N/A      3385      G   ...seed-version=20250904-180033.822000      140MiB |\n",
      "|    0   N/A  N/A     32885      G   /usr/share/code/code                        217MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d54724",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer.from_checkpoint(checkpoint_path, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66dd4d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embedding): Embedding(201088, 2880)\n",
       "  (block): ModuleList(\n",
       "    (0-23): 24 x TransformerBlock(\n",
       "      (attn): AttentionBlock(\n",
       "        (norm): RMSNorm()\n",
       "        (qkv): Linear(in_features=2880, out_features=5120, bias=True)\n",
       "        (out): Linear(in_features=4096, out_features=2880, bias=True)\n",
       "        (rope): RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): MLPBlock(\n",
       "        (norm): RMSNorm()\n",
       "        (gate): Linear(in_features=2880, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (unembedding): Linear(in_features=2880, out_features=201088, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cd7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight torch.Size([201088, 2880]) torch.bfloat16 579133440\n",
      "block.0.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.0.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.0.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.0.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.0.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.0.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.0.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.0.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.0.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.0.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.0.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.0.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.0.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.1.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.1.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.1.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.1.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.1.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.1.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.1.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.1.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.1.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.1.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.1.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.1.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.1.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.2.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.2.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.2.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.2.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.2.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.2.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.2.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.2.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.2.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.2.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.2.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.2.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.2.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.3.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.3.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.3.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.3.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.3.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.3.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.3.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.3.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.3.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.3.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.3.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.3.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.3.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.4.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.4.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.4.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.4.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.4.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.4.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.4.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.4.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.4.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.4.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.4.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.4.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.4.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.5.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.5.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.5.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.5.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.5.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.5.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.5.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.5.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.5.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.5.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.5.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.5.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.5.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.6.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.6.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.6.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.6.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.6.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.6.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.6.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.6.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.6.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.6.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.6.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.6.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.6.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.7.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.7.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.7.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.7.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.7.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.7.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.7.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.7.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.7.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.7.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.7.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.7.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.7.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.8.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.8.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.8.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.8.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.8.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.8.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.8.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.8.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.8.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.8.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.8.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.8.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.8.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.9.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.9.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.9.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.9.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.9.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.9.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.9.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.9.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.9.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.9.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.9.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.9.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.9.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.10.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.10.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.10.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.10.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.10.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.10.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.10.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.10.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.10.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.10.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.10.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.10.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.10.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.11.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.11.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.11.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.11.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.11.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.11.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.11.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.11.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.11.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.11.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.11.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.11.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.11.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.12.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.12.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.12.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.12.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.12.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.12.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.12.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.12.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.12.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.12.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.12.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.12.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.12.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.13.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.13.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.13.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.13.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.13.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.13.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.13.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.13.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.13.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.13.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.13.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.13.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.13.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.14.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.14.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.14.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.14.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.14.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.14.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.14.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.14.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.14.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.14.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.14.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.14.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.14.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.15.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.15.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.15.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.15.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.15.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.15.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.15.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.15.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.15.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.15.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.15.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.15.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.15.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.16.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.16.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.16.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.16.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.16.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.16.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.16.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.16.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.16.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.16.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.16.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.16.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.16.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.17.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.17.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.17.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.17.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.17.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.17.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.17.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.17.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.17.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.17.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.17.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.17.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.17.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.18.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.18.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.18.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.18.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.18.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.18.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.18.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.18.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.18.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.18.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.18.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.18.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.18.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.19.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.19.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.19.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.19.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.19.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.19.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.19.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.19.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.19.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.19.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.19.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.19.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.19.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.20.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.20.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.20.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.20.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.20.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.20.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.20.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.20.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.20.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.20.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.20.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.20.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.20.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.21.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.21.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.21.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.21.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.21.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.21.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.21.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.21.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.21.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.21.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.21.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.21.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.21.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.22.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.22.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.22.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.22.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.22.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.22.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.22.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.22.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.22.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.22.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.22.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.22.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.22.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.23.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.23.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.23.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.23.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.23.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.23.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.23.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.23.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.23.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.23.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.23.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.23.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.23.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "norm.scale torch.Size([2880]) torch.float32 2880\n",
      "unembedding.weight torch.Size([201088, 2880]) torch.bfloat16 579133440\n",
      "Number of parameters: 20914757184\n"
     ]
    }
   ],
   "source": [
    "num_parameters = 0\n",
    "parameters_state_dict = model.state_dict()\n",
    "for key, value in parameters_state_dict.items():\n",
    "    print(key, value.size(), value.dtype, value.numel())\n",
    "    num_parameters += value.numel()\n",
    "print(f\"Number of parameters: {num_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1572ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_model = TritonTransformer.from_checkpoint(checkpoint_path, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9945e04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embedding): Embedding(201088, 2880)\n",
       "  (block): ModuleList(\n",
       "    (0-23): 24 x TransformerBlock(\n",
       "      (attn): AttentionBlock(\n",
       "        (norm): RMSNorm()\n",
       "        (qkv): Linear(in_features=2880, out_features=5120, bias=True)\n",
       "        (out): Linear(in_features=4096, out_features=2880, bias=True)\n",
       "        (rope): RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): MLPBlock(\n",
       "        (norm): RMSNorm()\n",
       "        (gate): ParameterDict(\n",
       "            (bias): Parameter containing: [torch.cuda.BFloat16Tensor of size 32 (cuda:0)]\n",
       "            (weight): Parameter containing: [torch.cuda.BFloat16Tensor of size 2880x32 (cuda:0)]\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (unembedding): Linear(in_features=2880, out_features=201088, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa5946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep  5 09:57:11 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:01:00.0  On |                  Off |\n",
      "| 30%   42C    P8              25W / 450W |  18423MiB / 24564MiB |     21%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2087      G   /usr/lib/xorg/Xorg                          327MiB |\n",
      "|    0   N/A  N/A      2312      G   /usr/bin/gnome-shell                        109MiB |\n",
      "|    0   N/A  N/A      3385      G   ...seed-version=20250904-180033.822000      140MiB |\n",
      "|    0   N/A  N/A     32885      G   /usr/share/code/code                        248MiB |\n",
      "|    0   N/A  N/A    626115      C   ...a/anaconda3/envs/gpt_oss/bin/python    17574MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6241f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight torch.Size([201088, 2880]) torch.bfloat16 579133440\n",
      "block.0.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.0.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.0.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.0.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.0.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.0.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.0.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.0.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.0.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.0.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.0.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.0.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.0.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.1.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.1.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.1.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.1.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.1.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.1.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.1.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.1.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.1.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.1.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.1.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.1.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.1.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.2.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.2.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.2.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.2.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.2.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.2.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.2.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.2.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.2.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.2.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.2.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.2.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.2.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.3.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.3.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.3.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.3.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.3.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.3.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.3.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.3.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.3.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.3.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.3.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.3.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.3.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.4.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.4.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.4.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.4.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.4.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.4.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.4.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.4.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.4.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.4.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.4.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.4.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.4.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.5.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.5.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.5.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.5.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.5.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.5.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.5.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.5.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.5.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.5.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.5.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.5.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.5.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.6.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.6.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.6.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.6.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.6.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.6.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.6.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.6.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.6.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.6.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.6.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.6.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.6.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.7.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.7.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.7.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.7.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.7.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.7.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.7.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.7.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.7.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.7.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.7.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.7.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.7.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.8.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.8.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.8.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.8.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.8.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.8.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.8.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.8.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.8.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.8.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.8.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.8.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.8.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.9.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.9.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.9.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.9.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.9.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.9.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.9.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.9.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.9.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.9.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.9.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.9.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.9.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.10.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.10.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.10.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.10.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.10.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.10.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.10.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.10.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.10.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.10.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.10.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.10.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.10.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.11.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.11.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.11.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.11.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.11.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.11.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.11.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.11.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.11.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.11.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.11.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.11.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.11.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.12.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.12.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.12.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.12.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.12.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.12.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.12.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.12.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.12.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.12.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.12.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.12.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.12.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.13.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.13.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.13.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.13.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.13.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.13.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.13.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.13.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.13.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.13.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.13.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.13.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.13.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.14.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.14.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.14.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.14.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.14.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.14.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.14.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.14.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.14.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.14.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.14.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.14.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.14.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.15.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.15.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.15.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.15.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.15.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.15.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.15.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.15.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.15.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.15.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.15.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.15.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.15.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.16.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.16.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.16.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.16.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.16.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.16.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.16.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.16.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.16.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.16.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.16.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.16.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.16.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.17.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.17.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.17.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.17.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.17.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.17.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.17.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.17.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.17.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.17.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.17.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.17.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.17.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.18.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.18.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.18.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.18.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.18.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.18.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.18.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.18.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.18.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.18.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.18.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.18.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.18.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.19.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.19.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.19.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.19.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.19.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.19.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.19.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.19.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.19.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.19.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.19.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.19.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.19.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.20.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.20.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.20.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.20.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.20.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.20.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.20.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.20.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.20.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.20.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.20.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.20.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.20.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.21.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.21.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.21.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.21.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.21.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.21.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.21.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.21.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.21.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.21.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.21.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.21.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.21.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.22.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.22.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.22.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.22.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.22.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.22.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.22.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.22.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.22.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.22.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.22.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.22.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.22.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "block.23.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.23.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.23.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.23.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.23.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.23.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.23.mlp.mlp1_weight torch.Size([32, 5760, 1440]) torch.uint8 265420800\n",
      "block.23.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.23.mlp.mlp2_weight torch.Size([32, 5760, 720]) torch.uint8 132710400\n",
      "block.23.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.23.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.23.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.23.mlp.gate.weight torch.Size([2880, 32]) torch.bfloat16 92160\n",
      "norm.scale torch.Size([2880]) torch.float32 2880\n",
      "unembedding.weight torch.Size([201088, 2880]) torch.bfloat16 579133440\n",
      "Number of parameters: 11359608384\n"
     ]
    }
   ],
   "source": [
    "num_parameters = 0\n",
    "parameters_state_dict = triton_model.state_dict()\n",
    "for key, value in parameters_state_dict.items():\n",
    "    print(key, value.size(), value.dtype, value.numel())\n",
    "    num_parameters += value.numel()\n",
    "print(f\"Number of parameters: {num_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407bc99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
