{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2746414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_oss.torch.model import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1214cbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ksharma/dev/git/gpt-oss-scratch/gpt-oss-20b/original'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "checkpoint_path = os.path.join(os.getcwd(), \"gpt-oss-20b/original\")\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a84b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(num_hidden_layers=24,\n",
      "            num_experts=32,\n",
      "            experts_per_token=4,\n",
      "            vocab_size=201088,\n",
      "            hidden_size=2880,\n",
      "            intermediate_size=2880,\n",
      "            swiglu_limit=7.0,\n",
      "            head_dim=64,\n",
      "            num_attention_heads=64,\n",
      "            num_key_value_heads=8,\n",
      "            sliding_window=128,\n",
      "            initial_context_length=4096,\n",
      "            rope_theta=150000,\n",
      "            rope_scaling_factor=32.0,\n",
      "            rope_ntk_alpha=1,\n",
      "            rope_ntk_beta=32)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gpt_oss.torch.model import ModelConfig\n",
    "import pprint\n",
    "\n",
    "\n",
    "config_path = os.path.join(checkpoint_path, \"config.json\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    json_config = json.load(f)\n",
    "    config = ModelConfig(**json_config)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002f7da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-rank intermediate size: 2880\n"
     ]
    }
   ],
   "source": [
    "my_rank = 0\n",
    "world_size = 1\n",
    "per_rank_intermediate_size = config.intermediate_size // world_size\n",
    "print(f\"Per-rank intermediate size: {per_rank_intermediate_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a868637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from gpt_oss.torch.weights import Checkpoint\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "checkpoint = Checkpoint(checkpoint_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d54724",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer.from_checkpoint(checkpoint_path, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cd7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight torch.Size([201088, 2880]) torch.bfloat16 579133440\n",
      "block.0.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.0.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.0.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.0.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.0.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.0.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.0.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.0.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.0.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.0.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.0.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.0.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.0.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.1.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.1.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.1.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.1.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.1.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.1.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.1.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.1.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.1.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.1.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.1.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.1.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.1.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.2.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.2.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.2.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.2.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.2.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.2.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.2.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.2.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.2.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.2.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.2.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.2.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.2.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.3.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.3.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.3.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.3.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.3.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.3.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.3.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.3.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.3.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.3.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.3.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.3.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.3.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.4.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.4.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.4.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.4.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.4.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.4.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.4.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.4.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.4.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.4.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.4.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.4.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.4.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.5.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.5.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.5.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.5.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.5.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.5.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.5.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.5.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.5.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.5.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.5.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.5.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.5.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.6.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.6.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.6.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.6.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.6.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.6.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.6.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.6.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.6.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.6.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.6.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.6.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.6.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.7.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.7.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.7.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.7.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.7.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.7.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.7.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.7.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.7.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.7.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.7.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.7.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.7.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.8.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.8.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.8.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.8.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.8.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.8.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.8.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.8.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.8.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.8.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.8.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.8.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.8.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.9.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.9.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.9.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.9.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.9.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.9.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.9.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.9.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.9.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.9.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.9.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.9.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.9.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.10.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.10.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.10.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.10.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.10.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.10.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.10.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.10.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.10.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.10.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.10.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.10.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.10.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.11.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.11.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.11.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.11.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.11.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.11.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.11.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.11.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.11.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.11.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.11.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.11.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.11.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.12.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.12.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.12.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.12.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.12.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.12.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.12.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.12.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.12.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.12.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.12.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.12.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.12.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.13.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.13.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.13.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.13.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.13.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.13.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.13.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.13.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.13.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.13.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.13.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.13.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.13.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.14.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.14.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.14.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.14.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.14.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.14.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.14.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.14.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.14.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.14.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.14.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.14.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.14.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.15.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.15.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.15.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.15.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.15.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.15.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.15.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.15.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.15.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.15.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.15.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.15.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.15.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.16.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.16.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.16.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.16.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.16.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.16.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.16.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.16.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.16.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.16.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.16.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.16.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.16.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.17.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.17.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.17.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.17.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.17.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.17.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.17.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.17.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.17.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.17.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.17.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.17.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.17.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.18.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.18.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.18.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.18.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.18.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.18.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.18.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.18.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.18.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.18.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.18.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.18.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.18.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.19.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.19.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.19.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.19.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.19.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.19.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.19.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.19.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.19.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.19.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.19.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.19.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.19.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.20.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.20.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.20.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.20.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.20.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.20.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.20.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.20.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.20.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.20.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.20.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.20.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.20.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.21.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.21.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.21.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.21.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.21.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.21.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.21.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.21.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.21.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.21.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.21.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.21.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.21.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.22.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.22.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.22.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.22.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.22.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.22.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.22.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.22.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.22.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.22.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.22.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.22.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.22.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "block.23.attn.sinks torch.Size([64]) torch.bfloat16 64\n",
      "block.23.attn.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.23.attn.qkv.weight torch.Size([5120, 2880]) torch.bfloat16 14745600\n",
      "block.23.attn.qkv.bias torch.Size([5120]) torch.bfloat16 5120\n",
      "block.23.attn.out.weight torch.Size([2880, 4096]) torch.bfloat16 11796480\n",
      "block.23.attn.out.bias torch.Size([2880]) torch.bfloat16 2880\n",
      "block.23.mlp.mlp1_weight torch.Size([32, 5760, 2880]) torch.bfloat16 530841600\n",
      "block.23.mlp.mlp1_bias torch.Size([32, 5760]) torch.bfloat16 184320\n",
      "block.23.mlp.mlp2_weight torch.Size([32, 2880, 2880]) torch.bfloat16 265420800\n",
      "block.23.mlp.mlp2_bias torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.23.mlp.norm.scale torch.Size([2880]) torch.float32 2880\n",
      "block.23.mlp.gate.weight torch.Size([32, 2880]) torch.bfloat16 92160\n",
      "block.23.mlp.gate.bias torch.Size([32]) torch.bfloat16 32\n",
      "norm.scale torch.Size([2880]) torch.float32 2880\n",
      "unembedding.weight torch.Size([201088, 2880]) torch.bfloat16 579133440\n",
      "Number of parameters: 20914757184\n"
     ]
    }
   ],
   "source": [
    "num_parameters = 0\n",
    "parameters_state_dict = model.state_dict()\n",
    "for key, value in parameters_state_dict.items():\n",
    "    print(key, value.size(), value.dtype, value.numel())\n",
    "    num_parameters += value.numel()\n",
    "print(f\"Number of parameters: {num_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572ec66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
