{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeGraXIA4Mgf4GnSnpYs2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapilsh/gpt-oss-scratch/blob/main/gpt_oss_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yGYezJz4pcCC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UXigi18rlrZ9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "  def __init__(self, embedding_dimension: int, eps: float=1e-5):\n",
        "    super().__init__()\n",
        "    self.eps = eps\n",
        "    self.embedding_dimension = embedding_dimension\n",
        "    self.weight = nn.Parameter(torch.ones(embedding_dimension))\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    means = x.pow(2).mean(dim=-1, keepdim=True)\n",
        "    return (x * torch.rsqrt(means + self.eps)) * self.weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "example_batch = torch.randn(2, 3, 4)\n",
        "\n",
        "rms_norm = RMSNorm(embedding_dimension=example_batch.shape[-1])\n",
        "rmsnorm_pytorch = torch.nn.RMSNorm(example_batch.shape[-1], eps=1e-5)\n",
        "\n",
        "assert torch.allclose(rms_norm(example_batch), rmsnorm_pytorch(example_batch))"
      ],
      "metadata": {
        "id": "7SwqijzHmorK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How it works\n",
        "\n",
        "- Take the means of squared x over the last dimension = `means`\n",
        "- Divide all x's by `sqrt(e + means)` = `normalized_x`\n",
        "- Multiply `normalized_x` by `weights`: which is a trainable parameter\n",
        "\n",
        "Let's see an example"
      ],
      "metadata": {
        "id": "ZCWkd9A4m2Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Actual batch\")\n",
        "print(example_batch)\n",
        "print(\"-\" * 25)\n",
        "print(\"Squared batch\")\n",
        "powered_x = example_batch.pow(2)\n",
        "\n",
        "print(powered_x)\n",
        "\n",
        "print(\"-\" * 25)\n",
        "print(\"Means of powered x\")\n",
        "means = powered_x.mean(dim=-1, keepdim=True)\n",
        "\n",
        "print(means)\n",
        "print(\"-\" * 25)\n",
        "print(\"Reciprocal Root mean squared means\")\n",
        "rsqrt_means = torch.rsqrt(means + 1e-5)\n",
        "\n",
        "print(rsqrt_means)\n",
        "print(\"-\" * 25)\n",
        "print(\"Normalized batch\")\n",
        "normalized_x = example_batch * rsqrt_means\n",
        "\n",
        "print(normalized_x)\n",
        "print(\"-\" * 25)\n",
        "print(\"Weights\")\n",
        "weights = torch.ones(example_batch.size(-1))\n",
        "\n",
        "print(weights)\n",
        "print(\"-\" * 25)\n",
        "print(\"Final batch\")\n",
        "final_batch = normalized_x * rms_norm.weight\n",
        "\n",
        "print(final_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA6W_uqTmuQh",
        "outputId": "30f8094e-a792-44b0-e7a5-069688455523"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual batch\n",
            "tensor([[[ 0.3374, -0.1778, -0.3035, -0.5880],\n",
            "         [ 0.3486,  0.6603, -0.2196, -0.3792],\n",
            "         [-0.1606, -0.4015,  0.6957, -1.8061]],\n",
            "\n",
            "        [[ 1.8960, -0.1750,  1.3689, -1.6033],\n",
            "         [-0.7849, -1.4096, -0.4076,  0.7953],\n",
            "         [ 0.9985,  0.2212,  1.8319, -0.3378]]])\n",
            "-------------------------\n",
            "Powered batch\n",
            "tensor([[[0.1138, 0.0316, 0.0921, 0.3458],\n",
            "         [0.1215, 0.4361, 0.0482, 0.1438],\n",
            "         [0.0258, 0.1612, 0.4840, 3.2618]],\n",
            "\n",
            "        [[3.5947, 0.0306, 1.8739, 2.5705],\n",
            "         [0.6160, 1.9869, 0.1662, 0.6325],\n",
            "         [0.9971, 0.0490, 3.3558, 0.1141]]])\n",
            "-------------------------\n",
            "Means of powered x\n",
            "tensor([[[0.1458],\n",
            "         [0.1874],\n",
            "         [0.9832]],\n",
            "\n",
            "        [[2.0174],\n",
            "         [0.8504],\n",
            "         [1.1290]]])\n",
            "-------------------------\n",
            "Reciprocal Root mean squared means\n",
            "tensor([[[2.6186],\n",
            "         [2.3100],\n",
            "         [1.0085]],\n",
            "\n",
            "        [[0.7040],\n",
            "         [1.0844],\n",
            "         [0.9411]]])\n",
            "-------------------------\n",
            "Normalized batch\n",
            "tensor([[[ 0.8834, -0.4655, -0.7948, -1.5398],\n",
            "         [ 0.8053,  1.5254, -0.5074, -0.8759],\n",
            "         [-0.1619, -0.4049,  0.7016, -1.8214]],\n",
            "\n",
            "        [[ 1.3348, -0.1232,  0.9638, -1.1288],\n",
            "         [-0.8511, -1.5285, -0.4420,  0.8624],\n",
            "         [ 0.9398,  0.2082,  1.7241, -0.3180]]])\n",
            "-------------------------\n",
            "Weights\n",
            "tensor([1., 1., 1., 1.])\n",
            "-------------------------\n",
            "Final batch\n",
            "tensor([[[ 0.8834, -0.4655, -0.7948, -1.5398],\n",
            "         [ 0.8053,  1.5254, -0.5074, -0.8759],\n",
            "         [-0.1619, -0.4049,  0.7016, -1.8214]],\n",
            "\n",
            "        [[ 1.3348, -0.1232,  0.9638, -1.1288],\n",
            "         [-0.8511, -1.5285, -0.4420,  0.8624],\n",
            "         [ 0.9398,  0.2082,  1.7241, -0.3180]]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lm1uxjxrnp3c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}